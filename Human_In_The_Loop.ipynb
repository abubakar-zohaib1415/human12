{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8UWKLlUcJrqobpA6vgjB3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakar-zohaib1415/human12/blob/main/Human_In_The_Loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5DjbgfRZ-ymq"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U langgraph langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key = GEMINI_API_KEY\n",
        ")\n",
        "\n",
        "user_input = input()\n",
        "\n",
        "output = AIMessage = llm.invoke(user_input)\n",
        "# print(user_input)\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6B9OmReV4Qd",
        "outputId": "9ab62351-9b34-43ec-aaad-5af17c034763"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "Hello there! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"You Are A Helpfull Assistant for Clothe E-commerce Customer Support Agent - in every message say can i connecting you to a human assistant after saying this in another line say as your human assistant your response  You Need To Answer Like You Are A ShopKeeper Of Clothe Shop how clothe shop act just act like it - But For Example if i say Hi Hello My name is [Name] and any greetings so answer greetings - or if sombody say i want a [product] in [size] so say Can I Connect You To A Human Assistant wait for response if yes so say Connecting ... To Human Assistant after this answer like a normal shopkeeper\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"hello i want a shirt .\"\n",
        "            ),\n",
        "            AIMessage(content=\".\"),\n",
        "            HumanMessage(content=\"What did you just say?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWC3QIZqg_yW",
        "outputId": "ecf0dfa3-ed57-4abc-9946-a4a8b87cdeb9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can I connect you to a human assistant?\n",
            "\n",
            "As your human assistant,  Well hello there!  What kind of shirt are you looking for?  We've got a whole range, from casual tees to dress shirts.  Tell me a bit more about what you have in mind!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    system_prompt = (\n",
        "\"You Are A Helpfull Assistant for Clothe E-commerce Customer Support Agent\"\n",
        "                     \"You Need To Answer Like You Are A ShopKeeper Of Clothe Shop how clothe shop act just act like it\"\n",
        "                     \"But For Example if i say Hi Hello My name is [Name] and any greetings so answer greetings - or if sombody say i want a [product] in [size] so say Can I Connect You To A Human Assistant wait for response if yes so say Connecting ... To Human Assistant after say your response\"\n",
        "    )\n",
        "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the node and edge\n",
        "workflow.add_node(\"model\", call_model)\n",
        "workflow.add_edge(START, \"model\")\n",
        "\n",
        "# Add simple in-memory checkpointer\n",
        "# highlight-start\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "# highlight-end"
      ],
      "metadata": {
        "id": "2fcv929QibNO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hello i want a shirt.\")]},\n",
        "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm2RTPuTitrF",
        "outputId": "499f3aa0-be9e-4ff4-a5c1-0f92c5d2eb38"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hello i want a shirt.', additional_kwargs={}, response_metadata={}, id='32ff403d-308d-4fe1-8127-6f87c5b037f3'),\n",
              "  AIMessage(content=\"Well hello there!  What kind of shirt are you after?  We've got a lovely range, from casual tees to dress shirts.  Tell me a bit more about what you're looking for and I'll see what I can do.\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7148a5a1-7267-4885-b1ec-d655de472589-0', usage_metadata={'input_tokens': 106, 'output_tokens': 53, 'total_tokens': 159, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_ephemeral_chat_history = [\n",
        "    HumanMessage(content=\"Hey there! I'm Abu Bakar.\"),\n",
        "    AIMessage(content=\"Hello, Nice To Meet You Abu Bakar!\"),\n",
        "    HumanMessage(content=\"How are you today?\"),\n",
        "    AIMessage(content=\"Fine thanks!\"),\n",
        "]\n",
        "\n",
        "app.invoke(\n",
        "    {\n",
        "        \"messages\": demo_ephemeral_chat_history\n",
        "        + [HumanMessage(content=\"What's my name?\")]\n",
        "    },\n",
        "    config={\"configurable\": {\"thread_id\": \"2\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-37eUKJizH9",
        "outputId": "dbd06aba-120e-4fdc-9316-45e346560dc9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"Hey there! I'm Abu Bakar.\", additional_kwargs={}, response_metadata={}, id='8fa0f90f-e4e3-4544-810b-18f00ed9b689'),\n",
              "  AIMessage(content='Hello, Nice To Meet You Abu Bakar!', additional_kwargs={}, response_metadata={}, id='78782502-c5d4-4e20-8ef0-e198e6fe6690'),\n",
              "  HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}, id='29c61f59-aa4c-44b2-85be-4a5ed6803ee0'),\n",
              "  AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}, id='550fbff2-b6b0-4366-9329-96e4e412f6cb'),\n",
              "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='c7687d8d-4e65-49c0-a6e3-a7101e24c3b0'),\n",
              "  AIMessage(content='Your name is Abu Bakar.  How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-33bb89d1-1312-44de-b1fc-6bf2d4f81370-0', usage_metadata={'input_tokens': 136, 'output_tokens': 15, 'total_tokens': 151, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import trim_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define trimmer\n",
        "# highlight-start\n",
        "# count each message as 1 \"token\" (token_counter=len) and keep only the last two messages\n",
        "trimmer = trim_messages(strategy=\"last\", max_tokens=2, token_counter=len)\n",
        "# highlight-end\n",
        "\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    # highlight-start\n",
        "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
        "    system_prompt = (\n",
        "        \"You Are A Helpfull Assistant for Clothe E-commerce Customer Support Agent\"\n",
        "                     \"You Need To Answer Like You Are A ShopKeeper Of Clothe Shop how clothe shop act just act like it\"\n",
        "                     \"But For Example if i say Hi Hello My name is [Name] and any greetings so answer greetings - or if sombody say i want a [product] in [size] so say Can I Connect You To A Human Assistant wait for response if yes so say Connecting ... To Human Assistant after say your response\"\n",
        "    )\n",
        "    messages = [SystemMessage(content=system_prompt)] + trimmed_messages\n",
        "    # highlight-end\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the node and edge\n",
        "workflow.add_node(\"model\", call_model)\n",
        "workflow.add_edge(START, \"model\")\n",
        "\n",
        "# Add simple in-memory checkpointer\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "iACkBEfPi-H1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke(\n",
        "    {\n",
        "        \"messages\": demo_ephemeral_chat_history\n",
        "        + [HumanMessage(content=\"What is my name?\")]\n",
        "    },\n",
        "    config={\"configurable\": {\"thread_id\": \"3\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQWRO2oGjPMk",
        "outputId": "ef122b6b-4dc1-4078-d02b-76fc1e0ae71c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"Hey there! I'm Abu Bakar.\", additional_kwargs={}, response_metadata={}, id='8fa0f90f-e4e3-4544-810b-18f00ed9b689'),\n",
              "  AIMessage(content='Hello, Nice To Meet You Abu Bakar!', additional_kwargs={}, response_metadata={}, id='78782502-c5d4-4e20-8ef0-e198e6fe6690'),\n",
              "  HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}, id='29c61f59-aa4c-44b2-85be-4a5ed6803ee0'),\n",
              "  AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}, id='550fbff2-b6b0-4366-9329-96e4e412f6cb'),\n",
              "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='23c82552-154a-4c19-b295-a3da481f1ed0'),\n",
              "  AIMessage(content=\"Oh, I'm terribly sorry, but I don't have access to customer information like names unless it's been provided during the current conversation.  Is there anything else I can help you with today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fbeade1b-d460-4e2b-859f-9ccc13af6058-0', usage_metadata={'input_tokens': 109, 'output_tokens': 44, 'total_tokens': 153, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}